{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR Conv VGG.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPtdqvTh3X8+LuIEtb3Mtko"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"H4uPcvxDpBuT","colab_type":"code","outputId":"f6ba209c-8fdc-485c-8558-29f36010796c","executionInfo":{"status":"ok","timestamp":1587224505459,"user_tz":-120,"elapsed":5422424,"user":{"displayName":"Juan LÃ³pez","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjax0rdIgwQM-uwXcFTqJXInVefMJRfipMAvbKs6Q=s64","userId":"04861049710763598966"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from __future__ import print_function\n","import keras\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers.normalization import BatchNormalization as BN\n","from keras.layers import GaussianNoise as GN\n","from keras.optimizers import SGD\n","from keras.callbacks import LearningRateScheduler as LRS\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","batch_size = 100\n","num_classes = 10\n","epochs = 150\n","\n","\n","#### LOAD AND TRANSFORM\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","x_train /= 255\n","x_test /= 255\n","\n","print(x_train.shape)\n","print(x_test.shape)\n","\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","#### DATA AUGMENTATION\n","datagen = ImageDataGenerator(\n","            featurewise_center=True,\n","            featurewise_std_normalization=True,\n","            width_shift_range=0.2,\n","            height_shift_range=0.2,\n","            rotation_range=20,\n","            zoom_range=[1.0,1.2],\n","            horizontal_flip=True)\n","\n","datagen.fit(x_train)\n","\n","testdatagen = ImageDataGenerator(\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n",")\n","\n","testdatagen.fit(x_train)\n","\n","## DEF A BLOCK CONV VGG + BN + GN + MAXPOOL\n","def CBGN(model,filters,ishape=0):\n","  if (ishape!=0):\n","    model.add(Conv2D(filters, (3, 3), padding='same',\n","                  input_shape=ishape))\n","  else:\n","    model.add(Conv2D(filters, (3, 3), padding='same'))\n","  \n","  model.add(BN())\n","  model.add(GN(0.3))\n","  model.add(Activation('relu'))\n","  \n","  return model\n","\n","  \n","## DEF VGG TOPOLOGY   \n","def VGG_model(n):\n","\n","  if(n==11):\n","    c1, c2, c3, c4, c5 = 1, 1, 2, 2, 2\n","  elif(n==13):\n","    c1, c2, c3, c4, c5 = 2, 2, 2, 2, 2\n","  elif(n==16):\n","    c1, c2, c3, c4, c5 = 2, 2, 3, 3, 3\n","  elif(n==19):\n","    c1, c2, c3, c4, c5 = 2, 2, 4, 4, 4\n","  \n","  model = Sequential()\n","\n","  for i in range(c1):\n","    model=CBGN(model,64,x_train.shape[1:])\n","  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","  for i in range(c2):\n","    model=CBGN(model,128)\n","  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","  for i in range(c3):\n","    model=CBGN(model,256)\n","  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","  for i in range(c4):\n","    model=CBGN(model,512)\n","  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","  for i in range(c5):\n","    model=CBGN(model,512)\n","  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","\n","  model.add(Flatten())\n","  model.add(Dense(4096))\n","  model.add(Activation('relu'))\n","\n","  model.add(Dense(4096))\n","  model.add(Activation('relu'))\n","\n","  model.add(Dense(num_classes))\n","  model.add(Activation('softmax'))\n","\n","  return model\n","  \n","model = VGG_model(19)\n","model.summary()\n","\n","#### LEARNING RATE SCHEDULER\n","def scheduler(epoch):\n","  if epoch < 75:\n","    return .1\n","  elif epoch < 125:\n","    return 0.01\n","  else:\n","    return 0.001\n","\n","set_lr = LRS(scheduler)\n","\n","### OPTIM AND COMPILE\n","opt = SGD(lr=0.1, decay=1e-6)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","\n","### TRAINING AND VALIDATION\n","history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n","          steps_per_epoch=len(x_train) / batch_size, \n","          epochs=epochs,\n","          validation_data=testdatagen.flow(x_test, y_test),\n","          callbacks=[set_lr],\n","          shuffle=True,\n","          verbose=1)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 11s 0us/step\n","(50000, 32, 32, 3)\n","(10000, 32, 32, 3)\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","gaussian_noise_1 (GaussianNo (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n","_________________________________________________________________\n","gaussian_noise_2 (GaussianNo (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","gaussian_noise_3 (GaussianNo (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n","_________________________________________________________________\n","gaussian_noise_4 (GaussianNo (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","gaussian_noise_5 (GaussianNo (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","gaussian_noise_6 (GaussianNo (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","gaussian_noise_7 (GaussianNo (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 8, 8, 256)         590080    \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","gaussian_noise_8 (GaussianNo (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 4, 4, 512)         1180160   \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n","_________________________________________________________________\n","gaussian_noise_9 (GaussianNo (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 4, 4, 512)         2048      \n","_________________________________________________________________\n","gaussian_noise_10 (GaussianN (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","activation_10 (Activation)   (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 4, 4, 512)         2048      \n","_________________________________________________________________\n","gaussian_noise_11 (GaussianN (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","activation_11 (Activation)   (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 4, 4, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 4, 4, 512)         2048      \n","_________________________________________________________________\n","gaussian_noise_12 (GaussianN (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","activation_12 (Activation)   (None, 4, 4, 512)         0         \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","gaussian_noise_13 (GaussianN (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","activation_13 (Activation)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","gaussian_noise_14 (GaussianN (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","activation_14 (Activation)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv2d_15 (Conv2D)           (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","gaussian_noise_15 (GaussianN (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","activation_15 (Activation)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","conv2d_16 (Conv2D)           (None, 2, 2, 512)         2359808   \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 2, 2, 512)         2048      \n","_________________________________________________________________\n","gaussian_noise_16 (GaussianN (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","activation_16 (Activation)   (None, 2, 2, 512)         0         \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4096)              2101248   \n","_________________________________________________________________\n","activation_17 (Activation)   (None, 4096)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4096)              16781312  \n","_________________________________________________________________\n","activation_18 (Activation)   (None, 4096)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                40970     \n","_________________________________________________________________\n","activation_19 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 38,969,930\n","Trainable params: 38,958,922\n","Non-trainable params: 11,008\n","_________________________________________________________________\n","Epoch 1/150\n","500/500 [==============================] - 45s 90ms/step - loss: 1.7871 - accuracy: 0.3333 - val_loss: 1.3277 - val_accuracy: 0.4794\n","Epoch 2/150\n","500/500 [==============================] - 36s 72ms/step - loss: 1.3379 - accuracy: 0.5135 - val_loss: 1.4122 - val_accuracy: 0.4535\n","Epoch 3/150\n","500/500 [==============================] - 36s 71ms/step - loss: 1.1145 - accuracy: 0.6041 - val_loss: 0.7365 - val_accuracy: 0.6182\n","Epoch 4/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.9645 - accuracy: 0.6631 - val_loss: 1.5124 - val_accuracy: 0.7036\n","Epoch 5/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.8713 - accuracy: 0.6956 - val_loss: 0.6698 - val_accuracy: 0.6531\n","Epoch 6/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.8007 - accuracy: 0.7238 - val_loss: 1.9137 - val_accuracy: 0.7081\n","Epoch 7/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.7383 - accuracy: 0.7472 - val_loss: 1.1976 - val_accuracy: 0.7110\n","Epoch 8/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.6890 - accuracy: 0.7662 - val_loss: 1.1830 - val_accuracy: 0.7705\n","Epoch 9/150\n","500/500 [==============================] - 37s 73ms/step - loss: 0.6497 - accuracy: 0.7775 - val_loss: 0.7003 - val_accuracy: 0.6967\n","Epoch 10/150\n","500/500 [==============================] - 37s 73ms/step - loss: 0.6192 - accuracy: 0.7905 - val_loss: 1.0060 - val_accuracy: 0.7863\n","Epoch 11/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.5859 - accuracy: 0.7995 - val_loss: 1.0451 - val_accuracy: 0.7969\n","Epoch 12/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.5600 - accuracy: 0.8091 - val_loss: 1.1798 - val_accuracy: 0.7917\n","Epoch 13/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.5385 - accuracy: 0.8168 - val_loss: 0.2556 - val_accuracy: 0.8165\n","Epoch 14/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.5194 - accuracy: 0.8209 - val_loss: 0.1564 - val_accuracy: 0.8088\n","Epoch 15/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.4963 - accuracy: 0.8320 - val_loss: 0.3460 - val_accuracy: 0.8272\n","Epoch 16/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.4766 - accuracy: 0.8382 - val_loss: 1.2664 - val_accuracy: 0.7857\n","Epoch 17/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.4589 - accuracy: 0.8442 - val_loss: 0.2358 - val_accuracy: 0.8414\n","Epoch 18/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.4445 - accuracy: 0.8459 - val_loss: 0.3994 - val_accuracy: 0.8559\n","Epoch 19/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.4281 - accuracy: 0.8547 - val_loss: 0.0605 - val_accuracy: 0.8602\n","Epoch 20/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.4172 - accuracy: 0.8590 - val_loss: 0.1888 - val_accuracy: 0.8225\n","Epoch 21/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.4049 - accuracy: 0.8605 - val_loss: 1.2319 - val_accuracy: 0.8084\n","Epoch 22/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.3928 - accuracy: 0.8660 - val_loss: 0.2720 - val_accuracy: 0.8441\n","Epoch 23/150\n","500/500 [==============================] - 37s 74ms/step - loss: 0.3787 - accuracy: 0.8707 - val_loss: 0.6969 - val_accuracy: 0.8402\n","Epoch 24/150\n","500/500 [==============================] - 37s 74ms/step - loss: 0.3740 - accuracy: 0.8722 - val_loss: 0.5301 - val_accuracy: 0.8347\n","Epoch 25/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.3622 - accuracy: 0.8765 - val_loss: 0.2929 - val_accuracy: 0.8490\n","Epoch 26/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.3511 - accuracy: 0.8794 - val_loss: 0.1602 - val_accuracy: 0.8340\n","Epoch 27/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.3451 - accuracy: 0.8804 - val_loss: 0.6610 - val_accuracy: 0.8546\n","Epoch 28/150\n","500/500 [==============================] - 37s 74ms/step - loss: 0.3329 - accuracy: 0.8853 - val_loss: 0.1927 - val_accuracy: 0.8535\n","Epoch 29/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.3282 - accuracy: 0.8879 - val_loss: 0.1537 - val_accuracy: 0.8473\n","Epoch 30/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.3212 - accuracy: 0.8892 - val_loss: 0.0573 - val_accuracy: 0.8578\n","Epoch 31/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.3125 - accuracy: 0.8924 - val_loss: 0.4634 - val_accuracy: 0.8679\n","Epoch 32/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.3037 - accuracy: 0.8954 - val_loss: 1.0185 - val_accuracy: 0.8904\n","Epoch 33/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2917 - accuracy: 0.8993 - val_loss: 0.2911 - val_accuracy: 0.8721\n","Epoch 34/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.2882 - accuracy: 0.9003 - val_loss: 0.7984 - val_accuracy: 0.8872\n","Epoch 35/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.2780 - accuracy: 0.9040 - val_loss: 0.6673 - val_accuracy: 0.8870\n","Epoch 36/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.2760 - accuracy: 0.9061 - val_loss: 0.4348 - val_accuracy: 0.8879\n","Epoch 37/150\n","500/500 [==============================] - 37s 74ms/step - loss: 0.2719 - accuracy: 0.9076 - val_loss: 0.0707 - val_accuracy: 0.8893\n","Epoch 38/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2648 - accuracy: 0.9101 - val_loss: 0.2461 - val_accuracy: 0.8765\n","Epoch 39/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2578 - accuracy: 0.9097 - val_loss: 0.2786 - val_accuracy: 0.8829\n","Epoch 40/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2548 - accuracy: 0.9121 - val_loss: 0.6470 - val_accuracy: 0.8679\n","Epoch 41/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2472 - accuracy: 0.9147 - val_loss: 0.5331 - val_accuracy: 0.8869\n","Epoch 42/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2428 - accuracy: 0.9140 - val_loss: 0.0881 - val_accuracy: 0.8896\n","Epoch 43/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.2373 - accuracy: 0.9176 - val_loss: 0.1200 - val_accuracy: 0.8947\n","Epoch 44/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2364 - accuracy: 0.9179 - val_loss: 0.1370 - val_accuracy: 0.8860\n","Epoch 45/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2295 - accuracy: 0.9203 - val_loss: 0.5933 - val_accuracy: 0.8873\n","Epoch 46/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2241 - accuracy: 0.9217 - val_loss: 0.1157 - val_accuracy: 0.9088\n","Epoch 47/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2198 - accuracy: 0.9240 - val_loss: 0.8799 - val_accuracy: 0.8944\n","Epoch 48/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2167 - accuracy: 0.9243 - val_loss: 0.8061 - val_accuracy: 0.8884\n","Epoch 49/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2122 - accuracy: 0.9257 - val_loss: 0.0537 - val_accuracy: 0.8938\n","Epoch 50/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2054 - accuracy: 0.9290 - val_loss: 0.8071 - val_accuracy: 0.8921\n","Epoch 51/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.2023 - accuracy: 0.9303 - val_loss: 0.1625 - val_accuracy: 0.9008\n","Epoch 52/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1976 - accuracy: 0.9312 - val_loss: 0.7951 - val_accuracy: 0.8928\n","Epoch 53/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1937 - accuracy: 0.9329 - val_loss: 0.7320 - val_accuracy: 0.8959\n","Epoch 54/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1876 - accuracy: 0.9351 - val_loss: 0.1134 - val_accuracy: 0.8759\n","Epoch 55/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1871 - accuracy: 0.9340 - val_loss: 0.7418 - val_accuracy: 0.8918\n","Epoch 56/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1854 - accuracy: 0.9342 - val_loss: 0.6531 - val_accuracy: 0.8832\n","Epoch 57/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1823 - accuracy: 0.9356 - val_loss: 1.0162 - val_accuracy: 0.8820\n","Epoch 58/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1740 - accuracy: 0.9382 - val_loss: 0.7441 - val_accuracy: 0.8898\n","Epoch 59/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1777 - accuracy: 0.9378 - val_loss: 1.0376 - val_accuracy: 0.8839\n","Epoch 60/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1721 - accuracy: 0.9398 - val_loss: 0.1767 - val_accuracy: 0.9011\n","Epoch 61/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1654 - accuracy: 0.9409 - val_loss: 0.0383 - val_accuracy: 0.8920\n","Epoch 62/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1657 - accuracy: 0.9431 - val_loss: 0.9434 - val_accuracy: 0.9024\n","Epoch 63/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1625 - accuracy: 0.9430 - val_loss: 0.1381 - val_accuracy: 0.8974\n","Epoch 64/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1575 - accuracy: 0.9445 - val_loss: 0.7797 - val_accuracy: 0.8982\n","Epoch 65/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1609 - accuracy: 0.9443 - val_loss: 0.2991 - val_accuracy: 0.8990\n","Epoch 66/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1539 - accuracy: 0.9455 - val_loss: 0.0096 - val_accuracy: 0.9002\n","Epoch 67/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1519 - accuracy: 0.9470 - val_loss: 0.0933 - val_accuracy: 0.8958\n","Epoch 68/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1515 - accuracy: 0.9466 - val_loss: 0.1553 - val_accuracy: 0.8976\n","Epoch 69/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1437 - accuracy: 0.9497 - val_loss: 0.3057 - val_accuracy: 0.8998\n","Epoch 70/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1443 - accuracy: 0.9503 - val_loss: 0.4386 - val_accuracy: 0.8979\n","Epoch 71/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1445 - accuracy: 0.9497 - val_loss: 0.2403 - val_accuracy: 0.9049\n","Epoch 72/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1391 - accuracy: 0.9515 - val_loss: 0.5081 - val_accuracy: 0.9059\n","Epoch 73/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1358 - accuracy: 0.9516 - val_loss: 0.3982 - val_accuracy: 0.8943\n","Epoch 74/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.1362 - accuracy: 0.9515 - val_loss: 0.0832 - val_accuracy: 0.9162\n","Epoch 75/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.1344 - accuracy: 0.9529 - val_loss: 1.7666 - val_accuracy: 0.9079\n","Epoch 76/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0999 - accuracy: 0.9651 - val_loss: 0.0279 - val_accuracy: 0.9204\n","Epoch 77/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0862 - accuracy: 0.9704 - val_loss: 0.2599 - val_accuracy: 0.9224\n","Epoch 78/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0840 - accuracy: 0.9713 - val_loss: 0.4012 - val_accuracy: 0.9241\n","Epoch 79/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0775 - accuracy: 0.9729 - val_loss: 0.1397 - val_accuracy: 0.9231\n","Epoch 80/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0767 - accuracy: 0.9731 - val_loss: 0.0013 - val_accuracy: 0.9251\n","Epoch 81/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0763 - accuracy: 0.9732 - val_loss: 0.4713 - val_accuracy: 0.9241\n","Epoch 82/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0729 - accuracy: 0.9744 - val_loss: 0.6027 - val_accuracy: 0.9240\n","Epoch 83/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0716 - accuracy: 0.9748 - val_loss: 0.1881 - val_accuracy: 0.9260\n","Epoch 84/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0686 - accuracy: 0.9764 - val_loss: 0.6334 - val_accuracy: 0.9261\n","Epoch 85/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0693 - accuracy: 0.9756 - val_loss: 0.0525 - val_accuracy: 0.9265\n","Epoch 86/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0690 - accuracy: 0.9756 - val_loss: 0.5221 - val_accuracy: 0.9236\n","Epoch 87/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0675 - accuracy: 0.9762 - val_loss: 0.4101 - val_accuracy: 0.9240\n","Epoch 88/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0660 - accuracy: 0.9765 - val_loss: 0.0983 - val_accuracy: 0.9252\n","Epoch 89/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0662 - accuracy: 0.9775 - val_loss: 0.1583 - val_accuracy: 0.9280\n","Epoch 90/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0669 - accuracy: 0.9764 - val_loss: 0.0229 - val_accuracy: 0.9257\n","Epoch 91/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0637 - accuracy: 0.9768 - val_loss: 0.1100 - val_accuracy: 0.9276\n","Epoch 92/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0627 - accuracy: 0.9775 - val_loss: 0.3355 - val_accuracy: 0.9236\n","Epoch 93/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0614 - accuracy: 0.9778 - val_loss: 0.0059 - val_accuracy: 0.9261\n","Epoch 94/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0625 - accuracy: 0.9781 - val_loss: 0.3107 - val_accuracy: 0.9288\n","Epoch 95/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0605 - accuracy: 0.9790 - val_loss: 0.0012 - val_accuracy: 0.9268\n","Epoch 96/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0604 - accuracy: 0.9789 - val_loss: 0.0484 - val_accuracy: 0.9278\n","Epoch 97/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0602 - accuracy: 0.9791 - val_loss: 0.0022 - val_accuracy: 0.9252\n","Epoch 98/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0629 - accuracy: 0.9787 - val_loss: 0.0012 - val_accuracy: 0.9260\n","Epoch 99/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0599 - accuracy: 0.9791 - val_loss: 0.0426 - val_accuracy: 0.9262\n","Epoch 100/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0582 - accuracy: 0.9798 - val_loss: 0.7166 - val_accuracy: 0.9256\n","Epoch 101/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0587 - accuracy: 0.9789 - val_loss: 0.0094 - val_accuracy: 0.9264\n","Epoch 102/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0593 - accuracy: 0.9794 - val_loss: 0.0010 - val_accuracy: 0.9269\n","Epoch 103/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0578 - accuracy: 0.9796 - val_loss: 0.0737 - val_accuracy: 0.9275\n","Epoch 104/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 0.4380 - val_accuracy: 0.9270\n","Epoch 105/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0556 - accuracy: 0.9803 - val_loss: 0.0059 - val_accuracy: 0.9271\n","Epoch 106/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0568 - accuracy: 0.9801 - val_loss: 0.0048 - val_accuracy: 0.9277\n","Epoch 107/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0554 - accuracy: 0.9806 - val_loss: 0.8578 - val_accuracy: 0.9278\n","Epoch 108/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0570 - accuracy: 0.9798 - val_loss: 0.8192 - val_accuracy: 0.9262\n","Epoch 109/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0556 - accuracy: 0.9804 - val_loss: 0.0013 - val_accuracy: 0.9271\n","Epoch 110/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0588 - accuracy: 0.9796 - val_loss: 0.0015 - val_accuracy: 0.9266\n","Epoch 111/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.0552 - accuracy: 0.9807 - val_loss: 0.1871 - val_accuracy: 0.9266\n","Epoch 112/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0524 - accuracy: 0.9817 - val_loss: 0.2915 - val_accuracy: 0.9255\n","Epoch 113/150\n","500/500 [==============================] - 36s 73ms/step - loss: 0.0525 - accuracy: 0.9817 - val_loss: 0.1483 - val_accuracy: 0.9264\n","Epoch 114/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0526 - accuracy: 0.9825 - val_loss: 0.2657 - val_accuracy: 0.9270\n","Epoch 115/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0508 - accuracy: 0.9813 - val_loss: 0.1025 - val_accuracy: 0.9268\n","Epoch 116/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0556 - accuracy: 0.9810 - val_loss: 0.7646 - val_accuracy: 0.9280\n","Epoch 117/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0541 - accuracy: 0.9817 - val_loss: 0.2063 - val_accuracy: 0.9282\n","Epoch 118/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0510 - accuracy: 0.9822 - val_loss: 0.4809 - val_accuracy: 0.9271\n","Epoch 119/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0527 - accuracy: 0.9821 - val_loss: 0.5732 - val_accuracy: 0.9259\n","Epoch 120/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0503 - accuracy: 0.9825 - val_loss: 0.5906 - val_accuracy: 0.9262\n","Epoch 121/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0527 - accuracy: 0.9818 - val_loss: 0.3038 - val_accuracy: 0.9262\n","Epoch 122/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0509 - accuracy: 0.9823 - val_loss: 0.2813 - val_accuracy: 0.9263\n","Epoch 123/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0490 - accuracy: 0.9823 - val_loss: 0.0016 - val_accuracy: 0.9256\n","Epoch 124/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0522 - accuracy: 0.9818 - val_loss: 0.0094 - val_accuracy: 0.9264\n","Epoch 125/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0503 - accuracy: 0.9824 - val_loss: 0.6453 - val_accuracy: 0.9255\n","Epoch 126/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0490 - accuracy: 0.9828 - val_loss: 0.0083 - val_accuracy: 0.9280\n","Epoch 127/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0473 - accuracy: 0.9831 - val_loss: 0.1799 - val_accuracy: 0.9275\n","Epoch 128/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: 0.7897 - val_accuracy: 0.9279\n","Epoch 129/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0481 - accuracy: 0.9829 - val_loss: 0.0058 - val_accuracy: 0.9275\n","Epoch 130/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0480 - accuracy: 0.9828 - val_loss: 0.1570 - val_accuracy: 0.9281\n","Epoch 131/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0473 - accuracy: 0.9832 - val_loss: 0.8431 - val_accuracy: 0.9279\n","Epoch 132/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0475 - accuracy: 0.9834 - val_loss: 0.4038 - val_accuracy: 0.9280\n","Epoch 133/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0485 - accuracy: 0.9829 - val_loss: 0.9659 - val_accuracy: 0.9283\n","Epoch 134/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0453 - accuracy: 0.9840 - val_loss: 0.0317 - val_accuracy: 0.9278\n","Epoch 135/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0461 - accuracy: 0.9840 - val_loss: 0.4226 - val_accuracy: 0.9272\n","Epoch 136/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0455 - accuracy: 0.9836 - val_loss: 0.6687 - val_accuracy: 0.9275\n","Epoch 137/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0460 - accuracy: 0.9842 - val_loss: 0.1016 - val_accuracy: 0.9267\n","Epoch 138/150\n","500/500 [==============================] - 36s 71ms/step - loss: 0.0454 - accuracy: 0.9840 - val_loss: 0.2521 - val_accuracy: 0.9261\n","Epoch 139/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0453 - accuracy: 0.9847 - val_loss: 0.0100 - val_accuracy: 0.9270\n","Epoch 140/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0474 - accuracy: 0.9834 - val_loss: 0.0135 - val_accuracy: 0.9270\n","Epoch 141/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0458 - accuracy: 0.9841 - val_loss: 0.3723 - val_accuracy: 0.9266\n","Epoch 142/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0441 - accuracy: 0.9847 - val_loss: 0.5524 - val_accuracy: 0.9271\n","Epoch 143/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0473 - accuracy: 0.9835 - val_loss: 0.1376 - val_accuracy: 0.9270\n","Epoch 144/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0465 - accuracy: 0.9840 - val_loss: 0.1942 - val_accuracy: 0.9269\n","Epoch 145/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0465 - accuracy: 0.9835 - val_loss: 0.9192 - val_accuracy: 0.9271\n","Epoch 146/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0471 - accuracy: 0.9839 - val_loss: 0.7946 - val_accuracy: 0.9275\n","Epoch 147/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0439 - accuracy: 0.9843 - val_loss: 0.2404 - val_accuracy: 0.9270\n","Epoch 148/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0472 - accuracy: 0.9831 - val_loss: 0.2439 - val_accuracy: 0.9270\n","Epoch 149/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0472 - accuracy: 0.9838 - val_loss: 0.3716 - val_accuracy: 0.9272\n","Epoch 150/150\n","500/500 [==============================] - 36s 72ms/step - loss: 0.0447 - accuracy: 0.9846 - val_loss: 0.2381 - val_accuracy: 0.9275\n"],"name":"stdout"}]}]}