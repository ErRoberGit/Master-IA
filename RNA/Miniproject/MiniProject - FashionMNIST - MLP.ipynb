{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MiniProject - FashionMNIST - MLP.ipynb","provenance":[],"authorship_tag":"ABX9TyPpouKs6zm1gdSLrQC6m36k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZF5GZxJmsgew","colab_type":"code","outputId":"5c4d46b2-4771-46bc-91b7-757ee76b1a7c","executionInfo":{"status":"ok","timestamp":1581108773827,"user_tz":-60,"elapsed":2262062,"user":{"displayName":"Juan LÃ³pez","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBgUzCzE30s7_4IkyEOfNxGyZPTu_aDNuvfoOK0dw=s64","userId":"04861049710763598966"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from __future__ import print_function\n","\n","import keras\n","from keras.callbacks import LearningRateScheduler as LRS\n","from keras.layers import Dropout\n","from keras.datasets import fashion_mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Reshape\n","from keras.layers.normalization import BatchNormalization as BN\n","from keras.layers import GaussianNoise as GN\n","from keras.optimizers import SGD\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","batch_size = 100\n","num_classes = 10\n","epochs = 150\n","\n","# the data, shuffled and split between train and test sets\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","\n","\n","print(x_train.shape)\n","\n","# Mandatory to use ImageDataGenerator, it expects 4D Tensors\n","x_train = x_train.reshape(60000,28,28,1)\n","x_test = x_test.reshape(10000,28,28,1)\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","# Normalize [0..255]-->[0..1]\n","x_train /= 255\n","x_test /= 255\n","\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","## Data Augmentation with an ImageGenerator\n","datagen = ImageDataGenerator(\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=False)\n","\n","\n","## Model, note the reshape\n","model = Sequential()\n","model.add(Reshape(target_shape=(784,), input_shape=(28,28,1)))\n","model.add(GN(0.1))\n","\n","model.add(Dense(1024))\n","model.add(BN())\n","model.add(GN(0.1))\n","model.add(Activation('relu'))\n","\n","model.add(Dense(1024))\n","model.add(BN())\n","model.add(GN(0.1))\n","model.add(Activation('relu'))\n","\n","\"\"\"model.add(Dense(512))\n","model.add(BN())\n","model.add(GN(0.1))\n","model.add(Activation('relu'))\"\"\"\n","\n","\"\"\"model.add(Dense(1024))\n","model.add(BN())\n","model.add(GN(0.1))\n","model.add(Activation('relu'))\"\"\"\n","\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","##\n","\n","sgd=SGD(lr=0.1, decay=0.0, momentum=0.0)\n","\n","def scheduler(epoch):\n","    if epoch < 75:\n","        return .1\n","    elif epoch < 125:\n","        return 0.01\n","    else:\n","        return 0.001\n","\n","set_lr = LRS(scheduler)\n","\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=sgd,\n","              metrics=['accuracy'])\n","\n","\n","\n","history=model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n","                            steps_per_epoch=len(x_train) / batch_size, \n","                            epochs=epochs,\n","                            validation_data=(x_test, y_test),\n","                            callbacks=[set_lr], \n","                            verbose=1)\n","\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":2,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n","60000 train samples\n","10000 test samples\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","reshape_2 (Reshape)          (None, 784)               0         \n","_________________________________________________________________\n","gaussian_noise_4 (GaussianNo (None, 784)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1024)              803840    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","gaussian_noise_5 (GaussianNo (None, 1024)              0         \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","gaussian_noise_6 (GaussianNo (None, 1024)              0         \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 10)                10250     \n","=================================================================\n","Total params: 1,871,882\n","Trainable params: 1,867,786\n","Non-trainable params: 4,096\n","_________________________________________________________________\n","Epoch 1/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.6753 - acc: 0.7526 - val_loss: 0.5148 - val_acc: 0.8046\n","Epoch 2/150\n","600/600 [==============================] - 15s 26ms/step - loss: 0.5283 - acc: 0.8025 - val_loss: 0.5315 - val_acc: 0.8055\n","Epoch 3/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.4930 - acc: 0.8159 - val_loss: 0.4586 - val_acc: 0.8268\n","Epoch 4/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.4668 - acc: 0.8270 - val_loss: 0.4346 - val_acc: 0.8417\n","Epoch 5/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.4473 - acc: 0.8331 - val_loss: 0.4090 - val_acc: 0.8515\n","Epoch 6/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.4390 - acc: 0.8356 - val_loss: 0.3804 - val_acc: 0.8573\n","Epoch 7/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.4253 - acc: 0.8416 - val_loss: 0.3939 - val_acc: 0.8601\n","Epoch 8/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.4144 - acc: 0.8455 - val_loss: 0.4172 - val_acc: 0.8470\n","Epoch 9/150\n","600/600 [==============================] - 15s 26ms/step - loss: 0.4081 - acc: 0.8478 - val_loss: 0.3968 - val_acc: 0.8542\n","Epoch 10/150\n","600/600 [==============================] - 15s 24ms/step - loss: 0.4042 - acc: 0.8498 - val_loss: 0.3790 - val_acc: 0.8608\n","Epoch 11/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.3997 - acc: 0.8515 - val_loss: 0.3636 - val_acc: 0.8632\n","Epoch 12/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3931 - acc: 0.8534 - val_loss: 0.3855 - val_acc: 0.8501\n","Epoch 13/150\n","600/600 [==============================] - 14s 23ms/step - loss: 0.3893 - acc: 0.8535 - val_loss: 0.3816 - val_acc: 0.8602\n","Epoch 14/150\n","600/600 [==============================] - 14s 23ms/step - loss: 0.3866 - acc: 0.8548 - val_loss: 0.3517 - val_acc: 0.8746\n","Epoch 15/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.3812 - acc: 0.8560 - val_loss: 0.3624 - val_acc: 0.8709\n","Epoch 16/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.3791 - acc: 0.8586 - val_loss: 0.3432 - val_acc: 0.8776\n","Epoch 17/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.3724 - acc: 0.8594 - val_loss: 0.3779 - val_acc: 0.8629\n","Epoch 18/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3678 - acc: 0.8627 - val_loss: 0.3481 - val_acc: 0.8756\n","Epoch 19/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3678 - acc: 0.8608 - val_loss: 0.3442 - val_acc: 0.8762\n","Epoch 20/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3637 - acc: 0.8644 - val_loss: 0.3374 - val_acc: 0.8737\n","Epoch 21/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3591 - acc: 0.8651 - val_loss: 0.3401 - val_acc: 0.8774\n","Epoch 22/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.3593 - acc: 0.8652 - val_loss: 0.3218 - val_acc: 0.8854\n","Epoch 23/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.3553 - acc: 0.8667 - val_loss: 0.3498 - val_acc: 0.8764\n","Epoch 24/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.3519 - acc: 0.8682 - val_loss: 0.3412 - val_acc: 0.8765\n","Epoch 25/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.3497 - acc: 0.8686 - val_loss: 0.3350 - val_acc: 0.8809\n","Epoch 26/150\n","600/600 [==============================] - 15s 26ms/step - loss: 0.3504 - acc: 0.8681 - val_loss: 0.3247 - val_acc: 0.8811\n","Epoch 27/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.3454 - acc: 0.8711 - val_loss: 0.3399 - val_acc: 0.8744\n","Epoch 28/150\n","600/600 [==============================] - 15s 26ms/step - loss: 0.3454 - acc: 0.8704 - val_loss: 0.3203 - val_acc: 0.8835\n","Epoch 29/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3401 - acc: 0.8728 - val_loss: 0.3361 - val_acc: 0.8780\n","Epoch 30/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3397 - acc: 0.8712 - val_loss: 0.3320 - val_acc: 0.8792\n","Epoch 31/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3383 - acc: 0.8734 - val_loss: 0.3363 - val_acc: 0.8815\n","Epoch 32/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.3384 - acc: 0.8732 - val_loss: 0.3243 - val_acc: 0.8829\n","Epoch 33/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3347 - acc: 0.8746 - val_loss: 0.3163 - val_acc: 0.8857\n","Epoch 34/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3335 - acc: 0.8744 - val_loss: 0.3247 - val_acc: 0.8821\n","Epoch 35/150\n","600/600 [==============================] - 15s 26ms/step - loss: 0.3337 - acc: 0.8749 - val_loss: 0.3168 - val_acc: 0.8867\n","Epoch 36/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3320 - acc: 0.8744 - val_loss: 0.3181 - val_acc: 0.8871\n","Epoch 37/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.3272 - acc: 0.8769 - val_loss: 0.3303 - val_acc: 0.8810\n","Epoch 38/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3247 - acc: 0.8787 - val_loss: 0.3184 - val_acc: 0.8866\n","Epoch 39/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.3281 - acc: 0.8766 - val_loss: 0.3187 - val_acc: 0.8849\n","Epoch 40/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.3226 - acc: 0.8787 - val_loss: 0.3402 - val_acc: 0.8743\n","Epoch 41/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.3240 - acc: 0.8773 - val_loss: 0.3222 - val_acc: 0.8818\n","Epoch 42/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3214 - acc: 0.8791 - val_loss: 0.3224 - val_acc: 0.8850\n","Epoch 43/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3198 - acc: 0.8789 - val_loss: 0.3241 - val_acc: 0.8826\n","Epoch 44/150\n","600/600 [==============================] - 15s 24ms/step - loss: 0.3185 - acc: 0.8797 - val_loss: 0.3141 - val_acc: 0.8839\n","Epoch 45/150\n","600/600 [==============================] - 15s 24ms/step - loss: 0.3185 - acc: 0.8802 - val_loss: 0.3134 - val_acc: 0.8870\n","Epoch 46/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3163 - acc: 0.8814 - val_loss: 0.3125 - val_acc: 0.8878\n","Epoch 47/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3160 - acc: 0.8799 - val_loss: 0.3184 - val_acc: 0.8856\n","Epoch 48/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3146 - acc: 0.8809 - val_loss: 0.3077 - val_acc: 0.8899\n","Epoch 49/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3126 - acc: 0.8828 - val_loss: 0.3185 - val_acc: 0.8861\n","Epoch 50/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3124 - acc: 0.8820 - val_loss: 0.3101 - val_acc: 0.8891\n","Epoch 51/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3095 - acc: 0.8827 - val_loss: 0.3041 - val_acc: 0.8896\n","Epoch 52/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3096 - acc: 0.8825 - val_loss: 0.2989 - val_acc: 0.8925\n","Epoch 53/150\n","600/600 [==============================] - 15s 24ms/step - loss: 0.3087 - acc: 0.8827 - val_loss: 0.3014 - val_acc: 0.8912\n","Epoch 54/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3088 - acc: 0.8841 - val_loss: 0.3057 - val_acc: 0.8907\n","Epoch 55/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3069 - acc: 0.8844 - val_loss: 0.3230 - val_acc: 0.8825\n","Epoch 56/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3073 - acc: 0.8841 - val_loss: 0.2950 - val_acc: 0.8943\n","Epoch 57/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3028 - acc: 0.8844 - val_loss: 0.3076 - val_acc: 0.8890\n","Epoch 58/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3011 - acc: 0.8861 - val_loss: 0.3096 - val_acc: 0.8888\n","Epoch 59/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.3034 - acc: 0.8853 - val_loss: 0.2979 - val_acc: 0.8928\n","Epoch 60/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2995 - acc: 0.8852 - val_loss: 0.3002 - val_acc: 0.8888\n","Epoch 61/150\n","600/600 [==============================] - 14s 23ms/step - loss: 0.3027 - acc: 0.8870 - val_loss: 0.3092 - val_acc: 0.8881\n","Epoch 62/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.2991 - acc: 0.8877 - val_loss: 0.3181 - val_acc: 0.8847\n","Epoch 63/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2959 - acc: 0.8886 - val_loss: 0.2978 - val_acc: 0.8917\n","Epoch 64/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.2957 - acc: 0.8886 - val_loss: 0.2978 - val_acc: 0.8919\n","Epoch 65/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.2974 - acc: 0.8879 - val_loss: 0.3004 - val_acc: 0.8896\n","Epoch 66/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2938 - acc: 0.8893 - val_loss: 0.2953 - val_acc: 0.8930\n","Epoch 67/150\n","600/600 [==============================] - 15s 24ms/step - loss: 0.2968 - acc: 0.8880 - val_loss: 0.3070 - val_acc: 0.8868\n","Epoch 68/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2932 - acc: 0.8886 - val_loss: 0.3246 - val_acc: 0.8801\n","Epoch 69/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.2913 - acc: 0.8892 - val_loss: 0.2978 - val_acc: 0.8922\n","Epoch 70/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2913 - acc: 0.8897 - val_loss: 0.2988 - val_acc: 0.8930\n","Epoch 71/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2933 - acc: 0.8882 - val_loss: 0.2964 - val_acc: 0.8924\n","Epoch 72/150\n","600/600 [==============================] - 15s 26ms/step - loss: 0.2900 - acc: 0.8890 - val_loss: 0.2950 - val_acc: 0.8936\n","Epoch 73/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2886 - acc: 0.8903 - val_loss: 0.2977 - val_acc: 0.8929\n","Epoch 74/150\n","600/600 [==============================] - 15s 26ms/step - loss: 0.2882 - acc: 0.8906 - val_loss: 0.3064 - val_acc: 0.8893\n","Epoch 75/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2878 - acc: 0.8911 - val_loss: 0.2989 - val_acc: 0.8907\n","Epoch 76/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2727 - acc: 0.8967 - val_loss: 0.2787 - val_acc: 0.8988\n","Epoch 77/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2637 - acc: 0.9004 - val_loss: 0.2775 - val_acc: 0.8994\n","Epoch 78/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2610 - acc: 0.9022 - val_loss: 0.2746 - val_acc: 0.9009\n","Epoch 79/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2616 - acc: 0.9012 - val_loss: 0.2722 - val_acc: 0.9014\n","Epoch 80/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2624 - acc: 0.9013 - val_loss: 0.2715 - val_acc: 0.9005\n","Epoch 81/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2598 - acc: 0.9024 - val_loss: 0.2730 - val_acc: 0.9006\n","Epoch 82/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2572 - acc: 0.9022 - val_loss: 0.2717 - val_acc: 0.9007\n","Epoch 83/150\n","600/600 [==============================] - 15s 24ms/step - loss: 0.2586 - acc: 0.9018 - val_loss: 0.2726 - val_acc: 0.9005\n","Epoch 84/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.2590 - acc: 0.9008 - val_loss: 0.2708 - val_acc: 0.9016\n","Epoch 85/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.2575 - acc: 0.9042 - val_loss: 0.2703 - val_acc: 0.9014\n","Epoch 86/150\n","600/600 [==============================] - 15s 24ms/step - loss: 0.2601 - acc: 0.9019 - val_loss: 0.2713 - val_acc: 0.9023\n","Epoch 87/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.2577 - acc: 0.9026 - val_loss: 0.2706 - val_acc: 0.9014\n","Epoch 88/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2583 - acc: 0.9010 - val_loss: 0.2692 - val_acc: 0.9014\n","Epoch 89/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2557 - acc: 0.9036 - val_loss: 0.2730 - val_acc: 0.9008\n","Epoch 90/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.2519 - acc: 0.9044 - val_loss: 0.2692 - val_acc: 0.9019\n","Epoch 91/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2548 - acc: 0.9044 - val_loss: 0.2694 - val_acc: 0.9009\n","Epoch 92/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2534 - acc: 0.9039 - val_loss: 0.2702 - val_acc: 0.9015\n","Epoch 93/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2524 - acc: 0.9038 - val_loss: 0.2708 - val_acc: 0.9014\n","Epoch 94/150\n","600/600 [==============================] - 15s 26ms/step - loss: 0.2532 - acc: 0.9036 - val_loss: 0.2675 - val_acc: 0.9026\n","Epoch 95/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2531 - acc: 0.9051 - val_loss: 0.2681 - val_acc: 0.9032\n","Epoch 96/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2561 - acc: 0.9030 - val_loss: 0.2715 - val_acc: 0.9024\n","Epoch 97/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2528 - acc: 0.9045 - val_loss: 0.2719 - val_acc: 0.9014\n","Epoch 98/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2529 - acc: 0.9036 - val_loss: 0.2685 - val_acc: 0.9017\n","Epoch 99/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2528 - acc: 0.9055 - val_loss: 0.2695 - val_acc: 0.9028\n","Epoch 100/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2529 - acc: 0.9041 - val_loss: 0.2688 - val_acc: 0.9027\n","Epoch 101/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2516 - acc: 0.9041 - val_loss: 0.2707 - val_acc: 0.9027\n","Epoch 102/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2520 - acc: 0.9049 - val_loss: 0.2699 - val_acc: 0.9038\n","Epoch 103/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2517 - acc: 0.9047 - val_loss: 0.2705 - val_acc: 0.9012\n","Epoch 104/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.2524 - acc: 0.9045 - val_loss: 0.2694 - val_acc: 0.9032\n","Epoch 105/150\n","600/600 [==============================] - 14s 23ms/step - loss: 0.2519 - acc: 0.9062 - val_loss: 0.2678 - val_acc: 0.9032\n","Epoch 106/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2505 - acc: 0.9062 - val_loss: 0.2690 - val_acc: 0.9027\n","Epoch 107/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2493 - acc: 0.9068 - val_loss: 0.2698 - val_acc: 0.9030\n","Epoch 108/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2528 - acc: 0.9044 - val_loss: 0.2691 - val_acc: 0.9027\n","Epoch 109/150\n","600/600 [==============================] - 14s 23ms/step - loss: 0.2486 - acc: 0.9061 - val_loss: 0.2657 - val_acc: 0.9029\n","Epoch 110/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.2475 - acc: 0.9054 - val_loss: 0.2683 - val_acc: 0.9024\n","Epoch 111/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.2481 - acc: 0.9065 - val_loss: 0.2693 - val_acc: 0.9029\n","Epoch 112/150\n","600/600 [==============================] - 14s 23ms/step - loss: 0.2511 - acc: 0.9047 - val_loss: 0.2678 - val_acc: 0.9031\n","Epoch 113/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2501 - acc: 0.9053 - val_loss: 0.2702 - val_acc: 0.9010\n","Epoch 114/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2486 - acc: 0.9062 - val_loss: 0.2667 - val_acc: 0.9031\n","Epoch 115/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2503 - acc: 0.9056 - val_loss: 0.2693 - val_acc: 0.9028\n","Epoch 116/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2463 - acc: 0.9079 - val_loss: 0.2699 - val_acc: 0.9026\n","Epoch 117/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2473 - acc: 0.9072 - val_loss: 0.2679 - val_acc: 0.9028\n","Epoch 118/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.2483 - acc: 0.9059 - val_loss: 0.2651 - val_acc: 0.9039\n","Epoch 119/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.2475 - acc: 0.9062 - val_loss: 0.2654 - val_acc: 0.9037\n","Epoch 120/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.2447 - acc: 0.9075 - val_loss: 0.2665 - val_acc: 0.9031\n","Epoch 121/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.2455 - acc: 0.9085 - val_loss: 0.2685 - val_acc: 0.9028\n","Epoch 122/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.2471 - acc: 0.9066 - val_loss: 0.2653 - val_acc: 0.9053\n","Epoch 123/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.2465 - acc: 0.9066 - val_loss: 0.2660 - val_acc: 0.9044\n","Epoch 124/150\n","600/600 [==============================] - 15s 26ms/step - loss: 0.2475 - acc: 0.9070 - val_loss: 0.2659 - val_acc: 0.9047\n","Epoch 125/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2464 - acc: 0.9066 - val_loss: 0.2657 - val_acc: 0.9039\n","Epoch 126/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2474 - acc: 0.9054 - val_loss: 0.2645 - val_acc: 0.9048\n","Epoch 127/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2432 - acc: 0.9091 - val_loss: 0.2657 - val_acc: 0.9034\n","Epoch 128/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2434 - acc: 0.9077 - val_loss: 0.2656 - val_acc: 0.9042\n","Epoch 129/150\n","600/600 [==============================] - 15s 24ms/step - loss: 0.2454 - acc: 0.9077 - val_loss: 0.2653 - val_acc: 0.9039\n","Epoch 130/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2445 - acc: 0.9085 - val_loss: 0.2655 - val_acc: 0.9036\n","Epoch 131/150\n","600/600 [==============================] - 15s 24ms/step - loss: 0.2468 - acc: 0.9059 - val_loss: 0.2651 - val_acc: 0.9045\n","Epoch 132/150\n","600/600 [==============================] - 15s 24ms/step - loss: 0.2444 - acc: 0.9080 - val_loss: 0.2650 - val_acc: 0.9039\n","Epoch 133/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2426 - acc: 0.9067 - val_loss: 0.2651 - val_acc: 0.9039\n","Epoch 134/150\n","600/600 [==============================] - 14s 24ms/step - loss: 0.2441 - acc: 0.9076 - val_loss: 0.2650 - val_acc: 0.9040\n","Epoch 135/150\n","600/600 [==============================] - 14s 23ms/step - loss: 0.2445 - acc: 0.9077 - val_loss: 0.2650 - val_acc: 0.9038\n","Epoch 136/150\n","600/600 [==============================] - 15s 24ms/step - loss: 0.2438 - acc: 0.9081 - val_loss: 0.2651 - val_acc: 0.9036\n","Epoch 137/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2425 - acc: 0.9090 - val_loss: 0.2649 - val_acc: 0.9040\n","Epoch 138/150\n","600/600 [==============================] - 15s 26ms/step - loss: 0.2423 - acc: 0.9083 - val_loss: 0.2651 - val_acc: 0.9041\n","Epoch 139/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.2432 - acc: 0.9083 - val_loss: 0.2650 - val_acc: 0.9037\n","Epoch 140/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.2417 - acc: 0.9092 - val_loss: 0.2645 - val_acc: 0.9038\n","Epoch 141/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.2443 - acc: 0.9074 - val_loss: 0.2650 - val_acc: 0.9034\n","Epoch 142/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.2418 - acc: 0.9090 - val_loss: 0.2648 - val_acc: 0.9033\n","Epoch 143/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.2420 - acc: 0.9087 - val_loss: 0.2653 - val_acc: 0.9039\n","Epoch 144/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.2444 - acc: 0.9078 - val_loss: 0.2650 - val_acc: 0.9034\n","Epoch 145/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.2424 - acc: 0.9080 - val_loss: 0.2646 - val_acc: 0.9043\n","Epoch 146/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.2436 - acc: 0.9081 - val_loss: 0.2649 - val_acc: 0.9040\n","Epoch 147/150\n","600/600 [==============================] - 16s 27ms/step - loss: 0.2443 - acc: 0.9082 - val_loss: 0.2650 - val_acc: 0.9042\n","Epoch 148/150\n","600/600 [==============================] - 15s 26ms/step - loss: 0.2415 - acc: 0.9080 - val_loss: 0.2650 - val_acc: 0.9038\n","Epoch 149/150\n","600/600 [==============================] - 16s 26ms/step - loss: 0.2434 - acc: 0.9078 - val_loss: 0.2654 - val_acc: 0.9042\n","Epoch 150/150\n","600/600 [==============================] - 15s 25ms/step - loss: 0.2454 - acc: 0.9070 - val_loss: 0.2650 - val_acc: 0.9042\n","Test loss: 0.26503090847730637\n","Test accuracy: 0.9042\n"],"name":"stdout"}]}]}