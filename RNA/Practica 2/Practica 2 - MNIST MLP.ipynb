{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practica 2 - MNIST MLP.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"UJ5eLS6wFv6N","colab_type":"code","outputId":"8480c4eb-8a92-4679-d6c7-899e1d5e0b09","executionInfo":{"status":"ok","timestamp":1579627073210,"user_tz":-60,"elapsed":1861429,"user":{"displayName":"Juan LÃ³pez","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBgUzCzE30s7_4IkyEOfNxGyZPTu_aDNuvfoOK0dw=s64","userId":"04861049710763598966"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from __future__ import print_function\n","\n","import keras\n","from keras.callbacks import LearningRateScheduler as LRS\n","from keras.layers import Dropout\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Reshape\n","from keras.layers.normalization import BatchNormalization as BN\n","from keras.layers import GaussianNoise as GN\n","from keras.optimizers import SGD\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","batch_size = 100\n","num_classes = 10\n","epochs = 150\n","\n","# the data, shuffled and split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","\n","print(x_train.shape)\n","\n","# Mandatory to use ImageDataGenerator, it expects 4D Tensors\n","x_train = x_train.reshape(60000,28,28,1)\n","x_test = x_test.reshape(10000,28,28,1)\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","# Normalize [0..255]-->[0..1]\n","x_train /= 255\n","x_test /= 255\n","\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","## Data Augmentation with an ImageGenerator\n","datagen = ImageDataGenerator(\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=False)\n","\n","\n","## Model, note the reshape\n","model = Sequential()\n","model.add(Reshape(target_shape=(784,), input_shape=(28,28,1)))\n","model.add(GN(0.1))\n","\n","model.add(Dense(1024))\n","model.add(BN())\n","model.add(GN(0.1))\n","model.add(Activation('relu'))\n","\n","model.add(Dense(1024))\n","model.add(BN())\n","model.add(GN(0.1))\n","model.add(Activation('relu'))\n","\n","\"\"\"model.add(Dense(512))\n","model.add(BN())\n","model.add(GN(0.1))\n","model.add(Activation('relu'))\"\"\"\n","\n","\"\"\"model.add(Dense(1024))\n","model.add(BN())\n","model.add(GN(0.1))\n","model.add(Activation('relu'))\"\"\"\n","\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","##\n","\n","sgd=SGD(lr=0.1, decay=0.0, momentum=0.0)\n","\n","def scheduler(epoch):\n","    if epoch < 75:\n","        return .1\n","    elif epoch < 125:\n","        return 0.01\n","    else:\n","        return 0.001\n","\n","set_lr = LRS(scheduler)\n","\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=sgd,\n","              metrics=['accuracy'])\n","\n","\n","\n","history=model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n","                            steps_per_epoch=len(x_train) / batch_size, \n","                            epochs=epochs,\n","                            validation_data=(x_test, y_test),\n","                            callbacks=[set_lr], \n","                            verbose=1)\n","\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n","60000 train samples\n","10000 test samples\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","reshape_5 (Reshape)          (None, 784)               0         \n","_________________________________________________________________\n","gaussian_noise_13 (GaussianN (None, 784)               0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 1024)              803840    \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","gaussian_noise_14 (GaussianN (None, 1024)              0         \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 1024)              4096      \n","_________________________________________________________________\n","gaussian_noise_15 (GaussianN (None, 1024)              0         \n","_________________________________________________________________\n","activation_10 (Activation)   (None, 1024)              0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 10)                10250     \n","=================================================================\n","Total params: 1,871,882\n","Trainable params: 1,867,786\n","Non-trainable params: 4,096\n","_________________________________________________________________\n","Epoch 1/150\n","600/600 [==============================] - 14s 23ms/step - loss: 0.3646 - acc: 0.8862 - val_loss: 0.1236 - val_acc: 0.9645\n","Epoch 2/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.1836 - acc: 0.9443 - val_loss: 0.0899 - val_acc: 0.9736\n","Epoch 3/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.1510 - acc: 0.9533 - val_loss: 0.0764 - val_acc: 0.9749\n","Epoch 4/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.1304 - acc: 0.9590 - val_loss: 0.0681 - val_acc: 0.9782\n","Epoch 5/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.1189 - acc: 0.9632 - val_loss: 0.0644 - val_acc: 0.9791\n","Epoch 6/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.1088 - acc: 0.9658 - val_loss: 0.0561 - val_acc: 0.9807\n","Epoch 7/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.1021 - acc: 0.9684 - val_loss: 0.0590 - val_acc: 0.9799\n","Epoch 8/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0962 - acc: 0.9705 - val_loss: 0.0568 - val_acc: 0.9809\n","Epoch 9/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0892 - acc: 0.9715 - val_loss: 0.0462 - val_acc: 0.9848\n","Epoch 10/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0848 - acc: 0.9730 - val_loss: 0.0430 - val_acc: 0.9864\n","Epoch 11/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0818 - acc: 0.9744 - val_loss: 0.0430 - val_acc: 0.9868\n","Epoch 12/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0778 - acc: 0.9751 - val_loss: 0.0421 - val_acc: 0.9858\n","Epoch 13/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0731 - acc: 0.9765 - val_loss: 0.0427 - val_acc: 0.9874\n","Epoch 14/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0714 - acc: 0.9773 - val_loss: 0.0423 - val_acc: 0.9871\n","Epoch 15/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0698 - acc: 0.9777 - val_loss: 0.0391 - val_acc: 0.9870\n","Epoch 16/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0657 - acc: 0.9795 - val_loss: 0.0381 - val_acc: 0.9872\n","Epoch 17/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0648 - acc: 0.9795 - val_loss: 0.0407 - val_acc: 0.9862\n","Epoch 18/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0636 - acc: 0.9802 - val_loss: 0.0385 - val_acc: 0.9868\n","Epoch 19/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0625 - acc: 0.9799 - val_loss: 0.0398 - val_acc: 0.9871\n","Epoch 20/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0609 - acc: 0.9810 - val_loss: 0.0309 - val_acc: 0.9898\n","Epoch 21/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0600 - acc: 0.9808 - val_loss: 0.0373 - val_acc: 0.9878\n","Epoch 22/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0567 - acc: 0.9827 - val_loss: 0.0341 - val_acc: 0.9886\n","Epoch 23/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0579 - acc: 0.9815 - val_loss: 0.0358 - val_acc: 0.9874\n","Epoch 24/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0543 - acc: 0.9827 - val_loss: 0.0340 - val_acc: 0.9886\n","Epoch 25/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0535 - acc: 0.9829 - val_loss: 0.0370 - val_acc: 0.9871\n","Epoch 26/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0536 - acc: 0.9828 - val_loss: 0.0352 - val_acc: 0.9895\n","Epoch 27/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0501 - acc: 0.9835 - val_loss: 0.0344 - val_acc: 0.9879\n","Epoch 28/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0478 - acc: 0.9846 - val_loss: 0.0338 - val_acc: 0.9897\n","Epoch 29/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0494 - acc: 0.9845 - val_loss: 0.0335 - val_acc: 0.9895\n","Epoch 30/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0490 - acc: 0.9846 - val_loss: 0.0305 - val_acc: 0.9894\n","Epoch 31/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0477 - acc: 0.9851 - val_loss: 0.0277 - val_acc: 0.9911\n","Epoch 32/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0453 - acc: 0.9862 - val_loss: 0.0291 - val_acc: 0.9910\n","Epoch 33/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0443 - acc: 0.9860 - val_loss: 0.0302 - val_acc: 0.9895\n","Epoch 34/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0454 - acc: 0.9852 - val_loss: 0.0334 - val_acc: 0.9891\n","Epoch 35/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0451 - acc: 0.9859 - val_loss: 0.0327 - val_acc: 0.9890\n","Epoch 36/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0456 - acc: 0.9853 - val_loss: 0.0288 - val_acc: 0.9906\n","Epoch 37/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0450 - acc: 0.9854 - val_loss: 0.0338 - val_acc: 0.9897\n","Epoch 38/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0410 - acc: 0.9874 - val_loss: 0.0281 - val_acc: 0.9914\n","Epoch 39/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0409 - acc: 0.9866 - val_loss: 0.0266 - val_acc: 0.9910\n","Epoch 40/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0422 - acc: 0.9867 - val_loss: 0.0305 - val_acc: 0.9901\n","Epoch 41/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0395 - acc: 0.9874 - val_loss: 0.0289 - val_acc: 0.9913\n","Epoch 42/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0396 - acc: 0.9867 - val_loss: 0.0320 - val_acc: 0.9895\n","Epoch 43/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0404 - acc: 0.9868 - val_loss: 0.0303 - val_acc: 0.9896\n","Epoch 44/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0398 - acc: 0.9872 - val_loss: 0.0264 - val_acc: 0.9910\n","Epoch 45/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0364 - acc: 0.9881 - val_loss: 0.0250 - val_acc: 0.9916\n","Epoch 46/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0378 - acc: 0.9878 - val_loss: 0.0276 - val_acc: 0.9917\n","Epoch 47/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0361 - acc: 0.9887 - val_loss: 0.0301 - val_acc: 0.9904\n","Epoch 48/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0372 - acc: 0.9874 - val_loss: 0.0264 - val_acc: 0.9906\n","Epoch 49/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0362 - acc: 0.9884 - val_loss: 0.0269 - val_acc: 0.9920\n","Epoch 50/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0349 - acc: 0.9885 - val_loss: 0.0254 - val_acc: 0.9914\n","Epoch 51/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0339 - acc: 0.9888 - val_loss: 0.0268 - val_acc: 0.9910\n","Epoch 52/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0343 - acc: 0.9889 - val_loss: 0.0270 - val_acc: 0.9912\n","Epoch 53/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0347 - acc: 0.9887 - val_loss: 0.0212 - val_acc: 0.9929\n","Epoch 54/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0335 - acc: 0.9890 - val_loss: 0.0228 - val_acc: 0.9920\n","Epoch 55/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0333 - acc: 0.9894 - val_loss: 0.0246 - val_acc: 0.9910\n","Epoch 56/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0325 - acc: 0.9898 - val_loss: 0.0242 - val_acc: 0.9925\n","Epoch 57/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0334 - acc: 0.9891 - val_loss: 0.0229 - val_acc: 0.9915\n","Epoch 58/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0343 - acc: 0.9891 - val_loss: 0.0252 - val_acc: 0.9918\n","Epoch 59/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0321 - acc: 0.9899 - val_loss: 0.0246 - val_acc: 0.9910\n","Epoch 60/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0321 - acc: 0.9901 - val_loss: 0.0257 - val_acc: 0.9906\n","Epoch 61/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0313 - acc: 0.9896 - val_loss: 0.0241 - val_acc: 0.9927\n","Epoch 62/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0307 - acc: 0.9902 - val_loss: 0.0249 - val_acc: 0.9910\n","Epoch 63/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0312 - acc: 0.9895 - val_loss: 0.0279 - val_acc: 0.9902\n","Epoch 64/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0315 - acc: 0.9898 - val_loss: 0.0262 - val_acc: 0.9917\n","Epoch 65/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0310 - acc: 0.9901 - val_loss: 0.0262 - val_acc: 0.9920\n","Epoch 66/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0313 - acc: 0.9895 - val_loss: 0.0242 - val_acc: 0.9922\n","Epoch 67/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0298 - acc: 0.9901 - val_loss: 0.0254 - val_acc: 0.9910\n","Epoch 68/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0291 - acc: 0.9910 - val_loss: 0.0248 - val_acc: 0.9918\n","Epoch 69/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0298 - acc: 0.9902 - val_loss: 0.0237 - val_acc: 0.9924\n","Epoch 70/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0287 - acc: 0.9906 - val_loss: 0.0273 - val_acc: 0.9911\n","Epoch 71/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0295 - acc: 0.9902 - val_loss: 0.0224 - val_acc: 0.9915\n","Epoch 72/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0283 - acc: 0.9909 - val_loss: 0.0255 - val_acc: 0.9918\n","Epoch 73/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0291 - acc: 0.9906 - val_loss: 0.0272 - val_acc: 0.9915\n","Epoch 74/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0290 - acc: 0.9909 - val_loss: 0.0264 - val_acc: 0.9919\n","Epoch 75/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0280 - acc: 0.9910 - val_loss: 0.0229 - val_acc: 0.9914\n","Epoch 76/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0253 - acc: 0.9915 - val_loss: 0.0226 - val_acc: 0.9922\n","Epoch 77/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0222 - acc: 0.9927 - val_loss: 0.0221 - val_acc: 0.9926\n","Epoch 78/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0222 - acc: 0.9930 - val_loss: 0.0222 - val_acc: 0.9925\n","Epoch 79/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0221 - acc: 0.9927 - val_loss: 0.0220 - val_acc: 0.9929\n","Epoch 80/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0216 - acc: 0.9933 - val_loss: 0.0218 - val_acc: 0.9926\n","Epoch 81/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0218 - acc: 0.9931 - val_loss: 0.0215 - val_acc: 0.9928\n","Epoch 82/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0210 - acc: 0.9935 - val_loss: 0.0214 - val_acc: 0.9927\n","Epoch 83/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0194 - acc: 0.9935 - val_loss: 0.0213 - val_acc: 0.9927\n","Epoch 84/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0209 - acc: 0.9934 - val_loss: 0.0211 - val_acc: 0.9931\n","Epoch 85/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0201 - acc: 0.9937 - val_loss: 0.0214 - val_acc: 0.9929\n","Epoch 86/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0202 - acc: 0.9936 - val_loss: 0.0209 - val_acc: 0.9931\n","Epoch 87/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0196 - acc: 0.9935 - val_loss: 0.0208 - val_acc: 0.9933\n","Epoch 88/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0195 - acc: 0.9941 - val_loss: 0.0208 - val_acc: 0.9934\n","Epoch 89/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0187 - acc: 0.9939 - val_loss: 0.0203 - val_acc: 0.9933\n","Epoch 90/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0204 - acc: 0.9934 - val_loss: 0.0207 - val_acc: 0.9930\n","Epoch 91/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0191 - acc: 0.9942 - val_loss: 0.0211 - val_acc: 0.9930\n","Epoch 92/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0190 - acc: 0.9941 - val_loss: 0.0203 - val_acc: 0.9932\n","Epoch 93/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0187 - acc: 0.9942 - val_loss: 0.0204 - val_acc: 0.9933\n","Epoch 94/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0200 - acc: 0.9939 - val_loss: 0.0203 - val_acc: 0.9934\n","Epoch 95/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0183 - acc: 0.9942 - val_loss: 0.0201 - val_acc: 0.9931\n","Epoch 96/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.0201 - val_acc: 0.9933\n","Epoch 97/150\n","600/600 [==============================] - 13s 22ms/step - loss: 0.0197 - acc: 0.9941 - val_loss: 0.0200 - val_acc: 0.9933\n","Epoch 98/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0191 - acc: 0.9938 - val_loss: 0.0207 - val_acc: 0.9928\n","Epoch 99/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0192 - acc: 0.9940 - val_loss: 0.0204 - val_acc: 0.9932\n","Epoch 100/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0187 - acc: 0.9943 - val_loss: 0.0204 - val_acc: 0.9932\n","Epoch 101/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0205 - val_acc: 0.9931\n","Epoch 102/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.0199 - val_acc: 0.9934\n","Epoch 103/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0184 - acc: 0.9945 - val_loss: 0.0199 - val_acc: 0.9934\n","Epoch 104/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0183 - acc: 0.9944 - val_loss: 0.0205 - val_acc: 0.9932\n","Epoch 105/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.0200 - val_acc: 0.9929\n","Epoch 106/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0172 - acc: 0.9947 - val_loss: 0.0204 - val_acc: 0.9932\n","Epoch 107/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0181 - acc: 0.9949 - val_loss: 0.0200 - val_acc: 0.9935\n","Epoch 108/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0182 - acc: 0.9944 - val_loss: 0.0197 - val_acc: 0.9938\n","Epoch 109/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0178 - acc: 0.9945 - val_loss: 0.0198 - val_acc: 0.9935\n","Epoch 110/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0178 - acc: 0.9944 - val_loss: 0.0200 - val_acc: 0.9932\n","Epoch 111/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0183 - acc: 0.9938 - val_loss: 0.0198 - val_acc: 0.9936\n","Epoch 112/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0183 - acc: 0.9939 - val_loss: 0.0199 - val_acc: 0.9935\n","Epoch 113/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0182 - acc: 0.9942 - val_loss: 0.0202 - val_acc: 0.9933\n","Epoch 114/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0179 - acc: 0.9945 - val_loss: 0.0199 - val_acc: 0.9936\n","Epoch 115/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0175 - acc: 0.9946 - val_loss: 0.0197 - val_acc: 0.9934\n","Epoch 116/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0174 - acc: 0.9945 - val_loss: 0.0200 - val_acc: 0.9934\n","Epoch 117/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.0203 - val_acc: 0.9930\n","Epoch 118/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0185 - acc: 0.9941 - val_loss: 0.0202 - val_acc: 0.9932\n","Epoch 119/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0172 - acc: 0.9949 - val_loss: 0.0200 - val_acc: 0.9935\n","Epoch 120/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0181 - acc: 0.9942 - val_loss: 0.0198 - val_acc: 0.9931\n","Epoch 121/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0197 - val_acc: 0.9928\n","Epoch 122/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0182 - acc: 0.9943 - val_loss: 0.0194 - val_acc: 0.9934\n","Epoch 123/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0168 - acc: 0.9947 - val_loss: 0.0192 - val_acc: 0.9935\n","Epoch 124/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0180 - acc: 0.9947 - val_loss: 0.0196 - val_acc: 0.9933\n","Epoch 125/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0179 - acc: 0.9943 - val_loss: 0.0197 - val_acc: 0.9933\n","Epoch 126/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0169 - acc: 0.9950 - val_loss: 0.0199 - val_acc: 0.9933\n","Epoch 127/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0172 - acc: 0.9947 - val_loss: 0.0198 - val_acc: 0.9932\n","Epoch 128/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0194 - val_acc: 0.9935\n","Epoch 129/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0164 - acc: 0.9951 - val_loss: 0.0196 - val_acc: 0.9935\n","Epoch 130/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0169 - acc: 0.9948 - val_loss: 0.0197 - val_acc: 0.9933\n","Epoch 131/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0165 - acc: 0.9949 - val_loss: 0.0196 - val_acc: 0.9935\n","Epoch 132/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0170 - acc: 0.9945 - val_loss: 0.0196 - val_acc: 0.9935\n","Epoch 133/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0163 - acc: 0.9949 - val_loss: 0.0197 - val_acc: 0.9935\n","Epoch 134/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0157 - acc: 0.9951 - val_loss: 0.0198 - val_acc: 0.9934\n","Epoch 135/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0164 - acc: 0.9952 - val_loss: 0.0197 - val_acc: 0.9934\n","Epoch 136/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0173 - acc: 0.9948 - val_loss: 0.0197 - val_acc: 0.9935\n","Epoch 137/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0171 - acc: 0.9947 - val_loss: 0.0197 - val_acc: 0.9934\n","Epoch 138/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0163 - acc: 0.9951 - val_loss: 0.0198 - val_acc: 0.9934\n","Epoch 139/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0162 - acc: 0.9949 - val_loss: 0.0196 - val_acc: 0.9935\n","Epoch 140/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0174 - acc: 0.9948 - val_loss: 0.0196 - val_acc: 0.9935\n","Epoch 141/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0167 - acc: 0.9951 - val_loss: 0.0197 - val_acc: 0.9935\n","Epoch 142/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0169 - acc: 0.9950 - val_loss: 0.0196 - val_acc: 0.9935\n","Epoch 143/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0161 - acc: 0.9948 - val_loss: 0.0196 - val_acc: 0.9934\n","Epoch 144/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0166 - acc: 0.9950 - val_loss: 0.0197 - val_acc: 0.9934\n","Epoch 145/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0171 - acc: 0.9947 - val_loss: 0.0196 - val_acc: 0.9934\n","Epoch 146/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0196 - val_acc: 0.9935\n","Epoch 147/150\n","600/600 [==============================] - 12s 21ms/step - loss: 0.0166 - acc: 0.9951 - val_loss: 0.0195 - val_acc: 0.9935\n","Epoch 148/150\n","600/600 [==============================] - 13s 21ms/step - loss: 0.0163 - acc: 0.9950 - val_loss: 0.0197 - val_acc: 0.9935\n","Epoch 149/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0165 - acc: 0.9949 - val_loss: 0.0196 - val_acc: 0.9935\n","Epoch 150/150\n","600/600 [==============================] - 12s 20ms/step - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0197 - val_acc: 0.9934\n","Test loss: 0.019671181138556496\n","Test accuracy: 0.9934\n"],"name":"stdout"}]}]}